---
title: "Supported Models"
sidebarTitle: "Models"
description: "Train open source models on ART."
icon: "robot"
---

<Info>
  If you aren't sure which model to start with, we recommend using one of the
  [Qwen 2.5
  models](https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e).
  For a good balance of performance and size, start with [Qwen 2.5 14B
  Instruct](https://huggingface.co/Qwen/Qwen2.5-14B-Instruct).
</Info>

ART supports a wide variety of base models, with two constraining factors:

1. For single-device fine-tuning, the base model (along with some reasonable amount of context) must be able to fit on a H100 in a quantized state.
2. ART's dependencies (including Unsloth and vLLM) must support the model.

ART currently supports instruct-tuned models from the following providers. If you're curious about a model that is not listed below, ask in the Discord [#support](https://discord.com/channels/1359674493949448375/1359674622965973185) channel.

## Models

<Tabs>
  <Tab title="Gemma">
    <div className="full-width">
| Model    | Variant                                           | License |
| -------- | ------------------------------------------------- | ------- |
| Gemma 3n | [E2B](https://huggingface.co/google/gemma-3n-E2B) | gemma   |
|          | [E4B](https://huggingface.co/google/gemma-3n-E4B) | gemma   |
| Gemma 3  | [1 B](https://huggingface.co/google/gemma-3-1b)   | gemma   |
|          | [4 B](https://huggingface.co/google/gemma-3-4b)   | gemma   |
|          | [12 B](https://huggingface.co/google/gemma-3-12b) | gemma   |
|          | [27 B](https://huggingface.co/google/gemma-3-27b) | gemma   |
| Gemma 2  | [2 B](https://huggingface.co/google/gemma-2-2b)   | gemma   |
|          | [9 B](https://huggingface.co/google/gemma-2-9b)   | gemma   |
|          | [27 B](https://huggingface.co/google/gemma-2-27b) | gemma   |

    </div>

  </Tab>
  <Tab title="Qwen">
    <div className="full-width">

| Model          | Variant                                                 | License    |
| -------------- | ------------------------------------------------------- | ---------- |
| Qwen 3         | [0.6 B](https://huggingface.co/Qwen/Qwen3-0.6B)         | Apache-2.0 |
|                | [1.7 B](https://huggingface.co/Qwen/Qwen3-1.7B)         | Apache-2.0 |
|                | [4 B](https://huggingface.co/Qwen/Qwen3-4B)             | Apache-2.0 |
|                | [8 B](https://huggingface.co/Qwen/Qwen3-8B)             | Apache-2.0 |
|                | [14 B](https://huggingface.co/Qwen/Qwen3-14B)           | Apache-2.0 |
|                | [30B-A3B](https://huggingface.co/Qwen/Qwen3-30B-A3B)    | Apache-2.0 |
|                | [32 B](https://huggingface.co/Qwen/Qwen3-32B)           | Apache-2.0 |
| Qwen 2.5 Omni  | [3 B](https://huggingface.co/Qwen/Qwen2.5-Omni-3B)      | Apache-2.0 |
|                | [7 B](https://huggingface.co/Qwen/Qwen2.5-Omni-7B)      | Apache-2.0 |
| Qwen 2.5       | [0.5 B](https://huggingface.co/Qwen/Qwen2.5-0.5B)       | Apache-2.0 |
|                | [1.5 B](https://huggingface.co/Qwen/Qwen2.5-1.5B)       | Apache-2.0 |
|                | [3 B](https://huggingface.co/Qwen/Qwen2.5-3B)           | Apache-2.0 |
|                | [7 B](https://huggingface.co/Qwen/Qwen2.5-7B)           | Apache-2.0 |
|                | [14 B](https://huggingface.co/Qwen/Qwen2.5-14B)         | Apache-2.0 |
|                | [32 B](https://huggingface.co/Qwen/Qwen2.5-32B)         | Apache-2.0 |
| Qwen 2.5 Coder | [0.5 B](https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B) | Apache-2.0 |
|                | [1.5 B](https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B) | Apache-2.0 |
|                | [3 B](https://huggingface.co/Qwen/Qwen2.5-Coder-3B)     | Apache-2.0 |
|                | [7 B](https://huggingface.co/Qwen/Qwen2.5-Coder-7B)     | Apache-2.0 |
|                | [14 B](https://huggingface.co/Qwen/Qwen2.5-Coder-14B)   | Apache-2.0 |
|                | [32 B](https://huggingface.co/Qwen/Qwen2.5-Coder-32B)   | Apache-2.0 |

    </div>

  </Tab>
  <Tab title="DeepSeek">
    <div className="full-width">

| Model             | Variant                                                                          | License |
| ----------------- | -------------------------------------------------------------------------------- | ------- |
| DeepSeek-V3       | [V3-0324](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324)                   | MIT     |
|                   | [V3](https://huggingface.co/deepseek-ai/DeepSeek-V3)                             | MIT     |
| DeepSeek-R1       | [R1-0528](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528)                   | MIT     |
|                   | [R1-0528-Qwen3-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B) | MIT     |
|                   | [R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)                             | MIT     |
| R1 Zero           | [R1 Zero](https://huggingface.co/deepseek-ai/R1-Zero)                            | MIT     |
| Distill Llama 3   | [8 B](https://huggingface.co/deepseek-ai/Distill-Llama3-8B)                      | MIT     |
| Distill Llama 3.3 | [70 B](https://huggingface.co/deepseek-ai/Distill-Llama3.3-70B)                  | MIT     |
| Distill Qwen 2.5  | [1.5 B](https://huggingface.co/deepseek-ai/Distill-Qwen2.5-1.5B)                 | MIT     |

    </div>

  </Tab>
  <Tab title="Llama">
    <div className="full-width">
| Model     | Variant                                                                          | License           |
| --------- | -------------------------------------------------------------------------------- | ----------------- |
| Llama 4   | [Scout 17B-16E](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E)         | Llama 4 Community |
|           | [Maverick 17B-128E](https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E) | Llama 4 Community |
| Llama 3.3 | [70 B](https://huggingface.co/meta-llama/Llama-3.3-70B)                          | Llama 3 Community |
| Llama 3.2 | [1 B](https://huggingface.co/meta-llama/Llama-3.2-1B)                            | Llama 3 Community |
|           | [3 B](https://huggingface.co/meta-llama/Llama-3.2-3B)                            | Llama 3 Community |
|           | [11 B Vision](https://huggingface.co/meta-llama/Llama-3.2-11B-Vision)            | Llama 3 Community |
|           | [90 B Vision](https://huggingface.co/meta-llama/Llama-3.2-90B-Vision)            | Llama 3 Community |
| Llama 3.1 | [8 B](https://huggingface.co/meta-llama/Llama-3.1-8B)                            | Llama 3 Community |
|           | [70 B](https://huggingface.co/meta-llama/Llama-3.1-70B)                          | Llama 3 Community |
|           | [405 B](https://huggingface.co/meta-llama/Llama-3.1-405B)                        | Llama 3 Community |
| Llama 3   | [8 B](https://huggingface.co/meta-llama/Meta-Llama-3-8B)                         | Llama 3 Community |
|           | [70 B](https://huggingface.co/meta-llama/Meta-Llama-3-70B)                       | Llama 3 Community |
| Llama 2   | [7 B](https://huggingface.co/meta-llama/Llama-2-7b)                              | Llama 2 Community |

    </div>

  </Tab>

  <Tab title="Mistral">
    <div className="full-width">
| Model    | Variant                                                                   | License    |
| -------- | ------------------------------------------------------------------------- | ---------- |
| Mistral  | [Small 2409-22B](https://huggingface.co/mistralai/Mistral-Small-2409-22B) | Apache-2.0 |
|          | [Large 2407](https://huggingface.co/mistralai/Mistral-Large-2407)         | Apache-2.0 |
|          | [7B v0.3](https://huggingface.co/mistralai/Mistral-7B-v0.3)               | Apache-2.0 |
|          | [7B v0.2](https://huggingface.co/mistralai/Mistral-7B-v0.2)               | Apache-2.0 |
| Devstral | [Small 2505](https://huggingface.co/mistralai/Devstral-Small-2505)        | Apache-2.0 |

    </div>

  </Tab>
</Tabs>
