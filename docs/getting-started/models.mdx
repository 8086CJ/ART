---
title: "Supported Models"
sidebarTitle: "Models"
description: "Train open source models on ART."
icon: "robot"
---

ART supports a wide variety of base models, with two constraining factors:

1. For single-device fine-tuning, the base model (along with some reasonable amount of context) must be able to fit on a H100 in a quantized state.
2. ART's dependencies (including Unsloth and vLLM) must support the model.

Fortunately, the vast majority of models meet these requirements. If you're curious about a model that is not listed below, ask in the Discord #support channel.

## Instruct-tuned models

<Tabs>
  <Tab title="Qwen">
    <div className="full-width">
      <table>
        <thead>
          <tr>
            <th>Model</th>
            <th>Variant</th>
            <th>License</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Qwen 3</td>
            <td>[0.6&nbsp;B](https://huggingface.co/Qwen/Qwen3-0.6B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 3</td>
            <td>[1.7&nbsp;B](https://huggingface.co/Qwen/Qwen3-1.7B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 3</td>
            <td>[4&nbsp;B](https://huggingface.co/Qwen/Qwen3-4B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 3</td>
            <td>[8&nbsp;B](https://huggingface.co/Qwen/Qwen3-8B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 3</td>
            <td>[14&nbsp;B](https://huggingface.co/Qwen/Qwen3-14B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 3</td>
            <td>[30B-A3B](https://huggingface.co/Qwen/Qwen3-30B-A3B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 3</td>
            <td>[32&nbsp;B](https://huggingface.co/Qwen/Qwen3-32B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5&nbsp;Omni</td>
            <td>[3&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-Omni-3B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5&nbsp;Omni</td>
            <td>[7&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-Omni-7B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5</td>
            <td>[0.5 B](https://huggingface.co/Qwen/Qwen2.5-0.5B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5</td>
            <td>[1.5&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-1.5B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5</td>
            <td>[3&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-3B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5</td>
            <td>[7&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-7B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5</td>
            <td>[14&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-14B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5</td>
            <td>[32&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-32B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5&nbsp;Coder</td>
            <td>
              [0.5&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B)
            </td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5&nbsp;Coder</td>
            <td>
              [1.5&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B)
            </td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5&nbsp;Coder</td>
            <td>[3&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-Coder-3B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5&nbsp;Coder</td>
            <td>[7&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-Coder-7B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5&nbsp;Coder</td>
            <td>[14&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-Coder-14B)</td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Qwen 2.5&nbsp;Coder</td>
            <td>[32&nbsp;B](https://huggingface.co/Qwen/Qwen2.5-Coder-32B)</td>
            <td>Apache-2.0</td>
          </tr>
        </tbody>
      </table>
    </div>
  </Tab>
  <Tab title="DeepSeek">
    <div className="full-width">
      <table>
        <thead>
          <tr>
            <th>Model</th>
            <th>Variant</th>
            <th>License</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>DeepSeek-V3</td>
            <td>
              [V3-0324](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324)
            </td>
            <td>MIT</td>
          </tr>
          <tr>
            <td></td>
            <td>[V3](https://huggingface.co/deepseek-ai/DeepSeek-V3)</td>
            <td>MIT</td>
          </tr>
          <tr>
            <td>DeepSeek-R1</td>
            <td>
              [R1-0528](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528)
            </td>
            <td>MIT</td>
          </tr>
          <tr>
            <td></td>
            <td>
              [R1-0528-Qwen3-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B)
            </td>
            <td>MIT</td>
          </tr>
          <tr>
            <td></td>
            <td>[R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)</td>
            <td>MIT</td>
          </tr>
          <tr>
            <td>R1 Zero</td>
            <td>[R1 Zero](https://huggingface.co/deepseek-ai/R1-Zero)</td>
            <td>MIT</td>
          </tr>
          <tr>
            <td>Distill Llama 3</td>
            <td>
              [8&nbsp;B](https://huggingface.co/deepseek-ai/Distill-Llama3-8B)
            </td>
            <td>MIT</td>
          </tr>
          <tr>
            <td>Distill Llama 3.3</td>
            <td>
              [70&nbsp;B](https://huggingface.co/deepseek-ai/Distill-Llama3.3-70B)
            </td>
            <td>MIT</td>
          </tr>
          <tr>
            <td>Distill Qwen 2.5</td>
            <td>
              [1.5&nbsp;B](https://huggingface.co/deepseek-ai/Distill-Qwen2.5-1.5B)
            </td>
            <td>MIT</td>
          </tr>
        </tbody>
      </table>
    </div>
  </Tab>
  <Tab title="Llama">
    <div className="full-width">
      <table>
        <thead>
          <tr>
            <th>Model</th>
            <th>Variant</th>
            <th>License</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Llama 4</td>
            <td>
              [Scout&nbsp;17B-16E](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E)
            </td>
            <td>Llama&nbsp;4&nbsp;Community</td>
          </tr>
          <tr>
            <td></td>
            <td>
              [Maverick&nbsp;17B-128E](https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E)
            </td>
            <td>Llama&nbsp;4&nbsp;Community</td>
          </tr>
          <tr>
            <td>Llama 3.3</td>
            <td>
              [70&nbsp;B](https://huggingface.co/meta-llama/Llama-3.3-70B)
            </td>
            <td>Llama&nbsp;3&nbsp;Community</td>
          </tr>
          <tr>
            <td>Llama 3.2</td>
            <td>[1&nbsp;B](https://huggingface.co/meta-llama/Llama-3.2-1B)</td>
            <td>Llama&nbsp;3&nbsp;Community</td>
          </tr>
          <tr>
            <td></td>
            <td>[3&nbsp;B](https://huggingface.co/meta-llama/Llama-3.2-3B)</td>
            <td>Llama&nbsp;3&nbsp;Community</td>
          </tr>
          <tr>
            <td></td>
            <td>
              [11&nbsp;B&nbsp;Vision](https://huggingface.co/meta-llama/Llama-3.2-11B-Vision)
            </td>
            <td>Llama&nbsp;3&nbsp;Community</td>
          </tr>
          <tr>
            <td></td>
            <td>
              [90&nbsp;B&nbsp;Vision](https://huggingface.co/meta-llama/Llama-3.2-90B-Vision)
            </td>
            <td>Llama&nbsp;3&nbsp;Community</td>
          </tr>
          <tr>
            <td>Llama 3.1</td>
            <td>[8&nbsp;B](https://huggingface.co/meta-llama/Llama-3.1-8B)</td>
            <td>Llama&nbsp;3&nbsp;Community</td>
          </tr>
          <tr>
            <td></td>
            <td>
              [70&nbsp;B](https://huggingface.co/meta-llama/Llama-3.1-70B)
            </td>
            <td>Llama&nbsp;3&nbsp;Community</td>
          </tr>
          <tr>
            <td></td>
            <td>
              [405&nbsp;B](https://huggingface.co/meta-llama/Llama-3.1-405B)
            </td>
            <td>Llama&nbsp;3&nbsp;Community</td>
          </tr>
          <tr>
            <td>Llama 3</td>
            <td>
              [8&nbsp;B](https://huggingface.co/meta-llama/Meta-Llama-3-8B)
            </td>
            <td>Llama&nbsp;3&nbsp;Community</td>
          </tr>
          <tr>
            <td></td>
            <td>
              [70&nbsp;B](https://huggingface.co/meta-llama/Meta-Llama-3-70B)
            </td>
            <td>Llama&nbsp;3&nbsp;Community</td>
          </tr>
          <tr>
            <td>Llama 2</td>
            <td>[7&nbsp;B](https://huggingface.co/meta-llama/Llama-2-7b)</td>
            <td>Llama&nbsp;2&nbsp;Community</td>
          </tr>
        </tbody>
      </table>
    </div>
  </Tab>
  <Tab title="Gemma">
    <div className="full-width">
      <table>
        <thead>
          <tr>
            <th>Model</th>
            <th>Variant</th>
            <th>License</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Gemma 3n</td>
            <td>[E2B](https://huggingface.co/google/gemma-3n-E2B)</td>
            <td>gemma</td>
          </tr>
          <tr>
            <td></td>
            <td>[E4B](https://huggingface.co/google/gemma-3n-E4B)</td>
            <td>gemma</td>
          </tr>
          <tr>
            <td>Gemma 3</td>
            <td>[1&nbsp;B](https://huggingface.co/google/gemma-3-1b)</td>
            <td>gemma</td>
          </tr>
          <tr>
            <td></td>
            <td>[4&nbsp;B](https://huggingface.co/google/gemma-3-4b)</td>
            <td>gemma</td>
          </tr>
          <tr>
            <td></td>
            <td>[12&nbsp;B](https://huggingface.co/google/gemma-3-12b)</td>
            <td>gemma</td>
          </tr>
          <tr>
            <td></td>
            <td>[27&nbsp;B](https://huggingface.co/google/gemma-3-27b)</td>
            <td>gemma</td>
          </tr>
          <tr>
            <td>Gemma 2</td>
            <td>[2&nbsp;B](https://huggingface.co/google/gemma-2-2b)</td>
            <td>gemma</td>
          </tr>
          <tr>
            <td></td>
            <td>[9&nbsp;B](https://huggingface.co/google/gemma-2-9b)</td>
            <td>gemma</td>
          </tr>
          <tr>
            <td></td>
            <td>[27&nbsp;B](https://huggingface.co/google/gemma-2-27b)</td>
            <td>gemma</td>
          </tr>
        </tbody>
      </table>
    </div>
  </Tab>
  <Tab title="Mistral">
    <div className="full-width">
      <table>
        <thead>
          <tr>
            <th>Model</th>
            <th>Variant</th>
            <th>License</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Mistral</td>
            <td>
              [Small&nbsp;2409-22B](https://huggingface.co/mistralai/Mistral-Small-2409-22B)
            </td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td></td>
            <td>
              [Large&nbsp;2407](https://huggingface.co/mistralai/Mistral-Large-2407)
            </td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td></td>
            <td>
              [7B&nbsp;v0.3](https://huggingface.co/mistralai/Mistral-7B-v0.3)
            </td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td></td>
            <td>
              [7B&nbsp;v0.2](https://huggingface.co/mistralai/Mistral-7B-v0.2)
            </td>
            <td>Apache-2.0</td>
          </tr>
          <tr>
            <td>Devstral</td>
            <td>
              [Small&nbsp;2505](https://huggingface.co/mistralai/Devstral-Small-2505)
            </td>
            <td>Apache-2.0</td>
          </tr>
        </tbody>
      </table>
    </div>
  </Tab>
</Tabs>

## Base models

<Tabs>
  <Tab title="Qwen">
    <div className="full-width">
| Variant   | HF repo (base)                                                      | Licence          |
| --------- | ------------------------------------------------------------------- | ---------------- |
| 0.6 B     | [Qwen/Qwen3-0.6B](https://huggingface.co/Qwen/Qwen3-0.6B)           | Apache-2.0       |
| 1.7 B     | [Qwen/Qwen3-1.7B](https://huggingface.co/Qwen/Qwen3-1.7B)           | Apache-2.0       |
| 4 B       | [Qwen/Qwen3-4B](https://huggingface.co/Qwen/Qwen3-4B)               | Apache-2.0       |
| 8 B       | [Qwen/Qwen3-8B](https://huggingface.co/Qwen/Qwen3-8B)               | Apache-2.0       |
| 14 B      | [Qwen/Qwen3-14B](https://huggingface.co/Qwen/Qwen3-14B)             | Apache-2.0       |
| 30B-A3B   | [Qwen/Qwen3-30B-A3B](https://huggingface.co/Qwen/Qwen3-30B-A3B)     | Apache-2.0       |
| 32 B      | [Qwen/Qwen3-32B](https://huggingface.co/Qwen/Qwen3-32B)             | Apache-2.0       |
| 235B-A22B | [Qwen/Qwen3-235B-A22B](https://huggingface.co/Qwen/Qwen3-235B-A22B) | Apache-2.0       |
| 0.5 B     | [Qwen/Qwen2.5-0.5B](https://huggingface.co/Qwen/Qwen2.5-0.5B)       | Apache-2.0       |
| 1.5 B     | [Qwen/Qwen2.5-1.5B](https://huggingface.co/Qwen/Qwen2.5-1.5B)       | Apache-2.0       |
| 3 B       | [Qwen/Qwen2.5-3B](https://huggingface.co/Qwen/Qwen2.5-3B)           | Apache-2.0       |
| 7 B       | [Qwen/Qwen2.5-7B](https://huggingface.co/Qwen/Qwen2.5-7B)           | Apache-2.0       |
| 14 B      | [Qwen/Qwen2.5-14B](https://huggingface.co/Qwen/Qwen2.5-14B)         | Apache-2.0       |
| 32 B      | [Qwen/Qwen2.5-32B](https://huggingface.co/Qwen/Qwen2.5-32B)         | Apache-2.0       |
| 72 B      | [Qwen/Qwen2.5-72B](https://huggingface.co/Qwen/Qwen2.5-72B)         | **Qwen License** |
| 1.5 B     | [Qwen/Qwen2-1.5B](https://huggingface.co/Qwen/Qwen2-1.5B)           | Apache-2.0       |
| 7 B       | [Qwen/Qwen2-7B](https://huggingface.co/Qwen/Qwen2-7B)               | Apache-2.0       |

    </div>

  </Tab>
  <Tab title="DeepSeek">
      <div className="full-width">

| Variant          | HF repo (base)                                                                                        | Licence |
| ---------------- | ----------------------------------------------------------------------------------------------------- | ------- |
| V3               | [deepseek-ai/DeepSeek-V3](https://huggingface.co/deepseek-ai/DeepSeek-V3)                             | MIT     |
| V3-0324          | [deepseek-ai/DeepSeek-V3-0324](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324)                   | MIT     |
| R1-0528          | [deepseek-ai/DeepSeek-R1-0528](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528)                   | MIT     |
| R1-0528-Qwen3-8B | [deepseek-ai/DeepSeek-R1-0528-Qwen3-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B) | MIT     |
| R1               | [deepseek-ai/DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)                             | MIT     |
| R1-Zero          | [deepseek-ai/DeepSeek-R1-Zero](https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero)                   | MIT     |

</div>
  </Tab>
  <Tab title="Llama">
  | Variant                   | HF repo (base)                                                                                      | Licence           |
| ------------------------- | --------------------------------------------------------------------------------------------------- | ----------------- |
| Llama 4 Scout 17B-16E     | [meta-llama/Llama-4-Scout-17B-16E](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E)         | Llama 4 Community |
| Llama 4 Maverick 17B-128E | [meta-llama/Llama-4-Maverick-17B-128E](https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E) | Llama 4 Community |
| Llama 3.3 70 B            | [meta-llama/Llama-3.3-70B](https://huggingface.co/meta-llama/Llama-3.3-70B)                         | Llama 3 Community |
| Llama 3.2 1 B             | [meta-llama/Llama-3.2-1B](https://huggingface.co/meta-llama/Llama-3.2-1B)                           | Llama 3 Community |
| Llama 3.2 3 B             | [meta-llama/Llama-3.2-3B](https://huggingface.co/meta-llama/Llama-3.2-3B)                           | Llama 3 Community |
| Llama 3.2 11 B Vision     | [meta-llama/Llama-3.2-11B-Vision](https://huggingface.co/meta-llama/Llama-3.2-11B-Vision)           | Llama 3 Community |
| Llama 3.2 90 B Vision     | [meta-llama/Llama-3.2-90B-Vision](https://huggingface.co/meta-llama/Llama-3.2-90B-Vision)           | Llama 3 Community |
| Llama 3.1 8 B             | [meta-llama/Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-3.1-8B)                           | Llama 3 Community |
| Llama 3.1 70 B            | [meta-llama/Llama-3.1-70B](https://huggingface.co/meta-llama/Llama-3.1-70B)                         | Llama 3 Community |
| Llama 3 8 B               | [meta-llama/Meta-Llama-3-8B](https://huggingface.co/meta-llama/Meta-Llama-3-8B)                     | Llama 3 Community |
| Llama 2 7 B               | [meta-llama/Llama-2-7B](https://huggingface.co/meta-llama/Llama-2-7b)                               | Llama 2 Community |
| Llama 2 13 B              | [meta-llama/Llama-2-13B](https://huggingface.co/meta-llama/Llama-2-13b)                             | Llama 2 Community |

  </Tab>
  <Tab title="Gemma">
  | Variant | HF repo (base)                                                        | Licence       |
| ------- | --------------------------------------------------------------------- | ------------- |
| 1 B     | [google/gemma-3-1b-pt](https://huggingface.co/google/gemma-3-1b-pt)   | Gemma Licence |
| 4 B     | [google/gemma-3-4b-pt](https://huggingface.co/google/gemma-3-4b-pt)   | Gemma Licence |
| 12 B    | [google/gemma-3-12b-pt](https://huggingface.co/google/gemma-3-12b-pt) | Gemma Licence |
| 27 B    | [google/gemma-3-27b-pt](https://huggingface.co/google/gemma-3-27b-pt) | Gemma Licence |
| 2 B     | [google/gemma-2-2b](https://huggingface.co/google/gemma-2-2b)         | Gemma Licence |
| 9 B     | [google/gemma-2-9b](https://huggingface.co/google/gemma-2-9b)         | Gemma Licence |
| 27 B    | [google/gemma-2-27b](https://huggingface.co/google/gemma-2-27b)       | Gemma Licence |

  </Tab>
  <Tab title="Mistral">
  | Model         | Variant     | HF repo (base)                                                                                        | Licence    |
| ------------- | ----------- | ----------------------------------------------------------------------------------------------------- | ---------- |
| Mistral Small | 24 B (2501) | [mistralai/Mistral-Small-24B-Base-2501](https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501) | Apache-2.0 |
| Mistral NeMo  | 12 B (2407) | [mistralai/Mistral-NeMo-12B-2407](https://huggingface.co/mistralai/Mistral-Nemo-Base-2407)            | Apache-2.0 |
| Mistral       | 7 B v0.3    | [mistralai/Mistral-7B-v0.3](https://huggingface.co/mistralai/Mistral-7B-v0.3)                         | Apache-2.0 |
| Mistral       | 7 B v0.2    | [mistralai/Mistral-7B-v0.2](https://huggingface.co/mistralai/Mistral-7B-v0.2)                         | Apache-2.0 |
| Pixtral       | 12 B (2409) | [mistralai/Pixtral-12B-Base-2409](https://huggingface.co/mistralai/Pixtral-12B-Base-2409)             | Apache-2.0 |

  </Tab>
</Tabs>
