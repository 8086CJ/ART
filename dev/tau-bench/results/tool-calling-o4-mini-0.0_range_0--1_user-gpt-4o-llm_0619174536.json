[
  {
    "task_id": 6,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 0,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 4,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 9,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 5,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 1,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 2,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 7,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 8,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 3,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 10,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 13,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 15,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 12,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 17,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 11,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 16,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 19,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 14,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  },
  {
    "task_id": 18,
    "reward": 0.0,
    "info": {
      "error": "litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`",
      "traceback": "Traceback (most recent call last):\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/run.py\", line 78, in _run\n    res = agent.solve(\n          ^^^^^^^^^^^^\n  File \"/Users/saumya/ART/dev/tau-bench/tau_bench/agents/tool_calling_agent.py\", line 40, in solve\n    res = completion(\n          ^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1247, in wrapper\n    raise e\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 1125, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 3150, in completion\n    raise exception_type(\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/main.py\", line 1107, in completion\n    optional_params = get_optional_params(\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/utils.py\", line 3686, in get_optional_params\n    optional_params = litellm.OpenAIConfig().map_openai_params(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/openai.py\", line 214, in map_openai_params\n    return openaiOSeriesConfig.map_openai_params(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/saumya/miniconda3/lib/python3.12/site-packages/litellm/llms/openai/chat/o_series_transformation.py\", line 121, in map_openai_params\n    raise litellm.utils.UnsupportedParamsError(\nlitellm.exceptions.UnsupportedParamsError: litellm.UnsupportedParamsError: O-series models don't support temperature=0.0. Only temperature=1 is supported. To drop unsupported openai params from the call, set `litellm.drop_params = True`\n"
    },
    "traj": [],
    "trial": 0
  }
]